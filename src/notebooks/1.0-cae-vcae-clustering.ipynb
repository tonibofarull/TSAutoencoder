{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.metrics import calinski_harabasz_score, confusion_matrix\n",
    "\n",
    "from models.CAE import CAE\n",
    "from models.VCAE import VCAE\n",
    "from generate import sin_cos, arma, wind\n",
    "from train import train\n",
    "from utils import latent_space, choose_bottleneck, compute_distance_matrix\n",
    "\n",
    "import hydra\n",
    "from hydra.experimental import initialize, compose\n",
    "\n",
    "torch.manual_seed(4444)\n",
    "np.random.seed(4444)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(config_path=\"configs\"):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "\n",
    "cfg_dataset, cfg_model, cfg_train = cfg.dataset, cfg.model, cfg.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, n_valid, n_test = cfg_dataset.n_train, cfg_dataset.n_valid, cfg_dataset.n_test\n",
    "n = n_train+n_valid+n_test\n",
    "\n",
    "length = cfg_model.length # each observation is a vector of size (1,length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#X = sin_cos(n, length)\n",
    "#X = wind(num_elems=length)\n",
    "\n",
    "X1 = arma(n//3, length, ar=[0, -0.5] , ma=[0, 0.1])\n",
    "X2 = arma(n//3, length, ar=[0, 0, 0.7] , ma=[0, 0, 0.05])\n",
    "X3 = arma(n//3, length, ar=[0, 0, 0, 0, -0.6] , ma=[0, 0, 0, 0, 0.2])\n",
    "class1 = np.array([0]*(n//3), dtype=np.float32).reshape(n//3, 1, 1)\n",
    "class2 = np.array([1]*(n//3), dtype=np.float32).reshape(n//3, 1, 1)\n",
    "class3 = np.array([2]*(n//3), dtype=np.float32).reshape(n//3, 1, 1)\n",
    "X1 = np.append(X1, class1, 2)\n",
    "X2 = np.append(X2, class2, 2)\n",
    "X3 = np.append(X3, class3, 2)\n",
    "\n",
    "X = np.r_[X1,X2,X3]\n",
    "Y = np.array([1]*len(X1) + [2]*len(X2) + [3]*len(X3))\n",
    "\n",
    "idx = list(range(len(X)))\n",
    "np.random.shuffle(idx)\n",
    "X = X[idx]\n",
    "Y = Y[idx]\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "print(\"shape of X:\", X.shape)\n",
    "\n",
    "X_train, X_valid, X_test = X[:n_train], X[n_train:n_train+n_valid], X[n_train+n_valid:]\n",
    "Y_train, Y_valid, Y_test = Y[:n_train], Y[n_train:n_train+n_valid], Y[n_train+n_valid:]\n",
    "print(\"shape of X_train, X_valid, X_test:\", X_train.shape, X_valid.shape, X_test.shape)"
   ]
  },
  {
   "source": [
    "# Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CAE(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_losses, valid_losses = train(model, cfg_train, X_train, X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Cost\")\n",
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(valid_losses, label=\"validation\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"../saved_weights/vcae_kl0.25\")\n",
    "#model.load_state_dict(torch.load(\"../saved_weights/vcae_kl0.25\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average and std correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = model(X_test).detach().numpy()\n",
    "inp = X_test[:,:,:-1]\n",
    "\n",
    "# avg and std of cors\n",
    "cors = [scipy.stats.spearmanr(pred[i,0], inp[i,0]).correlation for i in range(n_test)]\n",
    "print(\"avg and std:\", np.mean(cors), np.std(cors))\n",
    "print()\n",
    "\n",
    "# plots\n",
    "n_plots = 4\n",
    "start = n_plots*0\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=n_plots, figsize=(25,5))\n",
    "for i in range(n_plots):\n",
    "    \n",
    "    axs[0,i].axis(\"off\")\n",
    "    axs[0,i].set_title(\"Original\")\n",
    "    axs[0,i].plot(inp[start+i,0])\n",
    "\n",
    "    axs[1,i].axis(\"off\")\n",
    "    axs[1,i].set_title(\"Reconstructed\")\n",
    "    axs[1,i].plot(pred[start+i,0])\n",
    "    print(\"cor:\", scipy.stats.spearmanr(pred[start+i,0], inp[start+i,0]).correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if cfg_model.bottleneck_nn == 2:\n",
    "    latent_space(model, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose bootleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#vals = choose_bottleneck(X_test, X_train, X_valid, length, M, Lf)\n",
    "#plt.plot([np.mean(x) for x in vals], \"-o\", [1]*len(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking important filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filter = 4*cfg_model.M\n",
    "w_per_filter = cfg_model.length-cfg_model.Lf+1 # weights per filter\n",
    "num_neurons = cfg_model.bottleneck_nn\n",
    "M = cfg_model.M \n",
    "\n",
    "if isinstance(model, VCAE):\n",
    "    num_neurons *= 2\n",
    "\n",
    "w = np.array([[torch.mean(torch.abs(model.full1.weight[j,i*w_per_filter:(i+1)*w_per_filter])).item() for i in range(num_filter)] for j in range(num_neurons)])\n",
    "\n",
    "x_axis_labels = [f\"{i}-d:{2**(i//M)}\" for i in range(w.shape[1])] # number of filter - d:dilatation\n",
    "sns.heatmap(w, cmap=\"coolwarm\", xticklabels=x_axis_labels) # y-axis => neuron of the bottleneck, x-axis => each position is one filter ordered by dilatation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering using bootlenecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bns = model(X_test, get_bottleneck=True).detach().numpy()\n",
    "chs = []\n",
    "for i in range(2,25):\n",
    "    clustering = AgglomerativeClustering(n_clusters=i)\n",
    "    clustering.fit(bns) \n",
    "    clus = clustering.labels_\n",
    "    ch = calinski_harabasz_score(bns,clus)\n",
    "    chs.append(ch)\n",
    "plt.plot(range(2,len(chs)+2), chs, \"o-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = AgglomerativeClustering(n_clusters=3)\n",
    "clustering.fit(bns)\n",
    "clus = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bns.shape[1] <= 10: # more than 10 plots is slow\n",
    "    sns.pairplot(pd.DataFrame(np.c_[bns,clus]), hue=bns.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1, d2 = 0, 1\n",
    "sns.scatterplot(x=bns[:,d1], y=bns[:,d2], hue=clus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(Y_test[clus == 0], return_counts=True))\n",
    "print(np.unique(Y_test[clus == 1], return_counts=True))\n",
    "print(np.unique(Y_test[clus == 2], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus += 1 # by exploration is the optimal option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Y_test, clus)\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, var = model(X_test, get_distribution=True)\n",
    "mean, var = mean.detach().numpy(), var.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = compute_distance_matrix(mean, var, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete: uses the maximum distances between all observations of the two sets.\n",
    "print(AgglomerativeClustering(n_clusters=3, affinity=\"precomputed\", linkage=\"complete\").fit(dm).labels_)\n",
    "print()\n",
    "# Average: uses the average of the distances of each observation of the two sets.\n",
    "print(AgglomerativeClustering(n_clusters=3, affinity=\"precomputed\", linkage=\"average\").fit(dm).labels_)\n",
    "print()\n",
    "# Single: uses the minimum of the distances between all observations of the two sets.\n",
    "print(AgglomerativeClustering(n_clusters=3, affinity=\"precomputed\", linkage=\"single\").fit(dm).labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus = AgglomerativeClustering(n_clusters=3, affinity=\"precomputed\", linkage=\"complete\").fit(dm).labels_\n",
    "print(np.unique(Y_test[clus == 0], return_counts=True))\n",
    "print(np.unique(Y_test[clus == 1], return_counts=True))\n",
    "print(np.unique(Y_test[clus == 2], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus = AgglomerativeClustering(n_clusters=3, affinity=\"precomputed\", linkage=\"complete\").fit(dm).labels_\n",
    "clus += 1\n",
    "cm = confusion_matrix(Y_test, clus)\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('.venv')",
   "metadata": {
    "interpreter": {
     "hash": "9ad813455595918db8ded92401fc4df387acd9b969db0ceaecd7473a35d1df90"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}