{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import AutoEncoder\n",
    "from generate import sin_cos, arma, wind\n",
    "from train import train\n",
    "from functional import *\n",
    "from utils import *\n",
    "\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "import pandas as pd\n",
    "\n",
    "torch.manual_seed(4444)\n",
    "np.random.seed(4444)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 700\n",
    "n_valid = 100\n",
    "n_test = 100\n",
    "n = n_train+n_valid+n_test\n",
    "\n",
    "length = 64 # each observation is a vector of size (1,length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#X = arma(n, length)\n",
    "X = wind(num_elems=length)\n",
    "#X = sin_cos(n, length)\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "\n",
    "X_train, X_valid, X_test = X[:n_train], X[n_train:n_train+n_valid], X[n_train+n_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "M = 1 # number of filters per conv\n",
    "Lf = 3 # size of the filters\n",
    "bottleneck_nn = 6\n",
    "model = AutoEncoder(length=length, Lf=Lf, M=M, bottleneck_nn=bottleneck_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "train_losses, valid_losses = train(model, X_train, X_valid, iters=3000, early_stopping_rounds=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Cost\")\n",
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(valid_losses, label=\"validation\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"../saved_weights/wind64_model\")\n",
    "#model.load_state_dict(torch.load(\"../saved_weights/wind6_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average and std correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred1 = model(X_test)\n",
    "\n",
    "print(f\"test loss: {my_mse(X_test,model(X_test)) + my_l2(model)}\")\n",
    "\n",
    "pred1 = pred1.detach().numpy()\n",
    "\n",
    "# mean cors\n",
    "cors = [scipy.stats.spearmanr(pred1[i,0], X_test[i,0]).correlation for i in range(n_test)]\n",
    "print(\"correlation avg and std:\", np.mean(cors), np.std(cors))\n",
    "print()\n",
    "\n",
    "# plot\n",
    "n_plots = 4\n",
    "start = n_plots*0\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=n_plots, figsize=(25,5))\n",
    "for i in range(n_plots):\n",
    "    \n",
    "    axs[0,i].axis(\"off\")\n",
    "    axs[0,i].set_title(\"Original\")\n",
    "    axs[0,i].plot(X_test[start+i,0])\n",
    "\n",
    "    axs[1,i].axis(\"off\")\n",
    "    axs[1,i].set_title(\"Reconstructed\")\n",
    "    axs[1,i].plot(pred1[start+i,0])\n",
    "    print(\"spearman:\", scipy.stats.spearmanr(pred1[start+i,0], X_test[start+i,0]).correlation)"
   ]
  },
  {
   "source": [
    "# Latent space"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if bottleneck_nn == 2:\n",
    "    latent_space(model, n=10)"
   ]
  },
  {
   "source": [
    "# Choose bootleneck"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vals = choose_bottleneck(X_test, X_train, X_valid, length, M, Lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([np.mean(x) for x in vals], \"-o\", [1]*len(vals))"
   ]
  },
  {
   "source": [
    "# Checking important filters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filter = 4*M\n",
    "w_per_filter = length-Lf+1 # weights per filter\n",
    "w = np.array([[torch.mean(torch.abs(model.full1.weight[j,i*w_per_filter:(i+1)*w_per_filter])).item() for i in range(num_filter)] for j in range(bottleneck_nn)])\n",
    "\n",
    "x_axis_labels = [f\"{i}-d:{2**(i//M)}\" for i in range(w.shape[1])] # number of filter - d:dilatation\n",
    "sns.heatmap(w, cmap=\"coolwarm\", xticklabels=x_axis_labels) # y-axis => neuron of the bottleneck, x-axis => each position is one filter ordered by dilatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = KMeans(n_clusters=2)\n",
    "clustering.fit(w.T) # tranposed -> cluster por columnas\n",
    "clustering.labels_"
   ]
  },
  {
   "source": [
    "# Clustering using bootleneck"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bns = model.forward(X_test, get_bottleneck=True).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chs = []\n",
    "for i in range(2,15):\n",
    "    clustering = KMeans(n_clusters=i)\n",
    "    clustering.fit(bns) \n",
    "    clus = clustering.labels_\n",
    "    ch = calinski_harabasz_score(bns,clus)\n",
    "    chs.append(ch)\n",
    "plt.plot(range(2,len(chs)+2), chs, \"o-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(pd.DataFrame(bns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "8ce69ff4a0e74b055a94681a9edd9b8e92b9c9328f9e6fc4ee9dad2d844e5a82"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}