{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch import optim\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import seaborn as sns\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "import os\r\n",
    "import random\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "from models.CAE import CAE\r\n",
    "from train import Trainer\r\n",
    "from interpretability import *\r\n",
    "from dataloader import ElectricDevices, normalize\r\n",
    "from utils import baseline\r\n",
    "\r\n",
    "from scipy.ndimage import gaussian_filter1d\r\n",
    "\r\n",
    "from pingouin import distance_corr # Szekely and Rizzo\r\n",
    "\r\n",
    "import hydra\r\n",
    "from hydra.experimental import initialize, initialize_config_dir, compose\r\n",
    "\r\n",
    "from utils import get_shapley_values, get_layer_attrs, get_neuron_attrs\r\n",
    "\r\n",
    "torch.manual_seed(4444)\r\n",
    "np.random.seed(4444)\r\n",
    "random.seed(4444)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize_config_dir(config_dir=os.path.abspath(\"configs\")):\r\n",
    "    cfg = compose(config_name=\"config\")\r\n",
    "print(cfg)\r\n",
    "\r\n",
    "diverging_colors = sns.color_palette(\"RdBu\", 9)\r\n",
    "\r\n",
    "data_train_ori, data_valid_ori, data_test_ori = ElectricDevices()\r\n",
    "data_train, data_valid, data_test = normalize(data_train_ori), normalize(data_valid_ori), normalize(data_test_ori)\r\n",
    "X_train, y_train = data_train[:,:,:-1], data_train[:,:,-1]\r\n",
    "X_valid, y_valid = data_valid[:,:,:-1], data_valid[:,:,-1]\r\n",
    "X_test, y_test = data_test[:,:,:-1], data_test[:,:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline(data_train, data_valid, data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CAE(cfg.model, num_classes=7)\r\n",
    "\r\n",
    "# torch.save(model.state_dict(), \"../saved_models/mod\")\r\n",
    "model.load_state_dict(torch.load(\"../saved_models/mod\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainer = Trainer(cfg.train)\r\n",
    "# train_losses, valid_losses = trainer.fit(model, data_train, data_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.title(\"Cost\")\r\n",
    "# plt.plot(train_losses, label=\"train\")\r\n",
    "# plt.plot(valid_losses, label=\"validation\")\r\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = [3279, 1156, 7419, 5046, 3323, 6485,5497]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = data_test[:,:,:-1], data_test[:,:,-1].numpy()\n",
    "X_testp, outclass_testp, bn = model(X_test, apply_noise=False)\n",
    "X_testp = X_testp.detach().numpy()\n",
    "probs_testp = model.classifier.get_probs(outclass_testp)\n",
    "y_testp = torch.argmax(probs_testp, dim=1).detach().numpy()\n",
    "\n",
    "# avg and std of cors\n",
    "cors = [distance_corr(X_testp[i,0], X_test[i,0].detach().numpy(), n_boot=None) for i in range(X_test.shape[0])]\n",
    "print(\"Distance Correlation avg and std:\", np.mean(cors), np.std(cors))\n",
    "print(\"NRMSE:\", (torch.sqrt(torch.mean(torch.square(X_test-X_testp)))/(torch.max(X_test)-torch.min(X_test))).item())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_testp)\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "\n",
    "print(\"Accuracy:\", np.sum(np.diag(cm))/np.sum(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploration of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# selected = np.random.choice(range(1000), 7)\r\n",
    "\r\n",
    "fig, axs = plt.subplots(nrows=2, ncols=len(selected), figsize=(25,5), constrained_layout=True)\r\n",
    "for i, x in enumerate(selected): #selected):\r\n",
    "    vals = data_test_ori[x,0,:-1]\r\n",
    "    min_v, max_v = torch.min(vals), torch.max(vals)\r\n",
    "    axs[0,i].set_title(f\"C: {int(y_test[x][0])} (min={min_v:.2f}, max={max_v:.2f})\")\r\n",
    "    axs[0,i].plot(X_test[x,0])\r\n",
    "    axs[0,i].axis(\"off\")\r\n",
    "    axs[0,i].set_ylim((0,1))\r\n",
    "\r\n",
    "    axs[1,i].set_title(f\"Pred: {int(y_testp[x])}\")\r\n",
    "    axs[1,i].plot(X_testp[x,0])\r\n",
    "    axs[1,i].axis(\"off\")\r\n",
    "    axs[1,i].set_ylim((0,1))\r\n",
    "\r\n",
    "    print(\"cor:\", distance_corr(X_testp[x,0], X_test[x,0], n_boot=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance of filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filter = model.k*model.M\r\n",
    "w_per_filter = model.length\r\n",
    "num_neurons = model.bottleneck_nn\r\n",
    "M = model.M\r\n",
    "\r\n",
    "w = np.array([[torch.mean(torch.abs(model.encoder.fc_conv_bn.weight[j,i*w_per_filter:(i+1)*w_per_filter])).item() for i in range(num_filter)] for j in range(num_neurons)])\r\n",
    "x_axis_labels = [f\"{i}-d:{model.dilation[i//M]}\" for i in range(w.shape[1])]\r\n",
    "\r\n",
    "_ = sns.heatmap(w, xticklabels=x_axis_labels, cmap=\"gray\", vmin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract bottlenecks from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, bn = model(X_train, False)\r\n",
    "bn = bn.detach().numpy()\r\n",
    "y_train_np = np.array(y_train, dtype=np.int8).flatten()\r\n",
    "\r\n",
    "baselines = np.mean(bn, axis=0) # mean value of each neuron on the whole training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution in each neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=5, ncols=5, figsize=(25,20), constrained_layout=True)\r\n",
    "axs[4,4].set_axis_off()\r\n",
    "for i in range(24):\r\n",
    "    aux = pd.DataFrame({\"x\": bn[:,i]})\r\n",
    "    axs.flat[i].set_title(f\"Neuron {i}\")\r\n",
    "    sns.histplot(data=aux, x=\"x\", ax=axs.flat[i], kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution in each neuron for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=5, ncols=5, figsize=(25,20), constrained_layout=True)\r\n",
    "axs[4,4].set_axis_off()\r\n",
    "for i in range(24):\r\n",
    "    aux = pd.DataFrame({\"Bottleneck\": bn[:,i], \"Class\": y_train_np})\r\n",
    "    axs.flat[i].set_title(f\"Neuron {i}\")\r\n",
    "    sns.kdeplot(data=aux, x=\"Bottleneck\", hue=\"Class\", palette=sns.color_palette(\"tab10\",7), ax=axs.flat[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input that maximizes neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(24):\r\n",
    "#     a1 = feature_visualization(model, i)\r\n",
    "#     plt.plot(a1, \"o-\")\r\n",
    "#     plt.title(f\"Neuron {i}\")\r\n",
    "#     plt.ylim(-0.05, 1.05)\r\n",
    "#     plt.savefig(f\"../plots/{i}.png\")\r\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input that maximizes class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(25,10), constrained_layout=True)\r\n",
    "# for i in range(7): #selected):\r\n",
    "#     a1 = feature_visualization_class(model, i)\r\n",
    "#     axs.flat[i].plot(a1)\r\n",
    "#     axs.flat[i].set_title(f\"Representant class {i}\")\r\n",
    "#     axs.flat[i].set_ylim(-0.05, 1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley Value Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance of input with respect to outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(25,10), constrained_layout=True)\r\n",
    "axs[1,3].set_axis_off()\r\n",
    "for i, x in enumerate(selected):\r\n",
    "    attrs = [shapley_sampling(X_test[x,0], model, feature=j, n_batches=1) for j in range(model.length)]\r\n",
    "    sns.heatmap(attrs, ax=axs.flat[i], center=0, cmap=diverging_colors, cbar_kws={\"orientation\": \"horizontal\"})\r\n",
    "\r\n",
    "    ax = axs.flat[i].twinx()\r\n",
    "    sns.lineplot(x=range(96), y=X_test[x,0], ax=ax)\r\n",
    "    line = ax.lines[0]\r\n",
    "    line.set_xdata(line.get_xdata()+0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance of bottleneck with respect the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(25,10))\r\n",
    "axs[1,3].set_axis_off()\r\n",
    "for i, x in enumerate(selected):\r\n",
    "    layer_attrs = np.array([shapley_sampling_bottleneck_output(X_test[x,0], model, j, baselines, n_batches=1) for j in range(model.bottleneck_nn)])\r\n",
    "    ax = sns.heatmap(layer_attrs, ax=axs.flat[i], cmap=diverging_colors, center=0, cbar_kws={\"orientation\": \"horizontal\"})\r\n",
    "\r\n",
    "    ax = axs.flat[i].twinx()\r\n",
    "    sns.lineplot(x=range(96), y=X_test[x,0], ax=ax)\r\n",
    "    line = ax.lines[0]\r\n",
    "    line.set_xdata(line.get_xdata()+0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance of input with respect the bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(25,10))\r\n",
    "axs[1,3].set_axis_off()\r\n",
    "for i, x in enumerate(selected):\r\n",
    "    layer_attrs = np.array([shapley_sampling_input_bottleneck(X_test[x,0], model, j, baselines, n_batches=1) for j in range(model.length)]).T\r\n",
    "    ax = sns.heatmap(layer_attrs, ax=axs.flat[i], cmap=diverging_colors, center=0, cbar_kws={\"orientation\": \"horizontal\"})\r\n",
    "\r\n",
    "    ax = axs.flat[i].twinx()\r\n",
    "    sns.lineplot(x=range(96), y=X_test[x,0], ax=ax)\r\n",
    "    line = ax.lines[0]\r\n",
    "    line.set_xdata(line.get_xdata()+0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance of bottleneck with respect the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(25,10))\r\n",
    "axs[1,3].set_axis_off()\r\n",
    "for i, x in enumerate(selected):\r\n",
    "    layer_attrs = np.array([shapley_sampling_bottleneck_class(X_test[x,0], model, j, baselines, n_batches=1) for j in range(model.bottleneck_nn)])\r\n",
    "    ax = sns.heatmap(layer_attrs, ax=axs.flat[i], cmap=diverging_colors, center=0, cbar_kws={\"orientation\": \"horizontal\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance of input with respect class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(25,10))\r\n",
    "axs[1,3].set_axis_off()\r\n",
    "for i, x in enumerate(selected):\r\n",
    "    layer_attrs = np.array([shapley_sampling_input_class(X_test[x,0], model, j, baselines, n_batches=1) for j in range(model.length)]).T\r\n",
    "    ax = sns.heatmap(layer_attrs, ax=axs.flat[i], cmap=diverging_colors, center=0, cbar_kws={\"orientation\": \"horizontal\"})\r\n",
    "\r\n",
    "    ax = axs.flat[i].twinx()\r\n",
    "    sns.lineplot(x=range(96), y=X_test[x,0], ax=ax)\r\n",
    "    line = ax.lines[0]\r\n",
    "    line.set_xdata(line.get_xdata()+0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('.venv')",
   "metadata": {
    "interpreter": {
     "hash": "3d0a349251b803ce89bf9e449a94f1b8464b3ca029752d5a5598c6dc74984378"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}