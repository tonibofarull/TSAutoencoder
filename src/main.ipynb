{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch import optim\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import seaborn as sns\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "import os\r\n",
    "import random\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "from models.CAE import CAE\r\n",
    "from train import Trainer\r\n",
    "from interpretability import *\r\n",
    "from dataloader import ElectricDevices, normalize\r\n",
    "from utils import baseline\r\n",
    "\r\n",
    "from scipy.ndimage import gaussian_filter1d\r\n",
    "\r\n",
    "from pingouin import distance_corr # Szekely and Rizzo\r\n",
    "\r\n",
    "import hydra\r\n",
    "from hydra.experimental import initialize, initialize_config_dir, compose\r\n",
    "\r\n",
    "from utils import get_shapley_values, get_layer_attrs, get_neuron_attrs\r\n",
    "\r\n",
    "torch.manual_seed(4444)\r\n",
    "np.random.seed(4444)\r\n",
    "random.seed(4444)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'M': 4, 'Lf': 3, 'length': 96, 'bottleneck_nn': 24, 'lmd': 1.0979131326372968e-05, 'alpha': 0.05}, 'train': {'verbose': True, 'shuffle': True, 'batch_size': 64, 'iters': 300, 'early_stopping_rounds': 23, 'lr': 0.001706322160346846}}\n"
     ]
    }
   ],
   "source": [
    "with initialize_config_dir(config_dir=os.path.abspath(\"configs\")):\r\n",
    "    cfg = compose(config_name=\"config\")\r\n",
    "print(cfg)\r\n",
    "\r\n",
    "diverging_colors = sns.color_palette(\"RdBu\", 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_ori, data_valid_ori, data_test_ori = ElectricDevices()\n",
    "data_train, data_valid, data_test = normalize(data_train_ori), normalize(data_valid_ori), normalize(data_test_ori)\n",
    "X_train, y_train = data_train[:,:,:-1], data_train[:,:,-1]\n",
    "X_valid, y_valid = data_valid[:,:,:-1], data_valid[:,:,-1]\n",
    "X_test, y_test = data_test[:,:,:-1], data_test[:,:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline(data_train, data_valid, data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CAE(cfg.model, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), \"../saved_models/mod\")\r\n",
    "model.load_state_dict(torch.load(\"../saved_models/mod\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainer = Trainer(cfg.train)\r\n",
    "# train_losses, valid_losses = trainer.fit(model, data_train, data_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.title(\"Cost\")\r\n",
    "# plt.plot(train_losses, label=\"train\")\r\n",
    "# plt.plot(valid_losses, label=\"validation\")\r\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking important filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filter = model.k*model.M\r\n",
    "w_per_filter = model.length\r\n",
    "num_neurons = model.bottleneck_nn\r\n",
    "M = model.M\r\n",
    "\r\n",
    "w = np.array([[torch.mean(torch.abs(model.encoder.fc_conv_bn.weight[j,i*w_per_filter:(i+1)*w_per_filter])).item() for i in range(num_filter)] for j in range(num_neurons)])\r\n",
    "x_axis_labels = [f\"{i}-d:{model.dilation[i//M]}\" for i in range(w.shape[1])]\r\n",
    "# x_axis_labels.append(\"Input\")\r\n",
    "# w = np.concatenate((w, torch.mean(model.encoder.full_conv_bn.weight[:,:-96], axis=1).detach().numpy().reshape(24,1)), axis=1)\r\n",
    "\r\n",
    "_ = sns.heatmap(w, xticklabels=x_axis_labels, cmap=\"gray\", vmin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using as input the arrays with only 1 one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average and std correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = [3279, 1156, 7419, 5046, 3323, 6485,5497]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = data_test[:,:,:-1], data_test[:,:,-1].numpy()\n",
    "X_testp, outclass_testp, bn = model(X_test, apply_noise=False)\n",
    "X_testp = X_testp.detach().numpy()\n",
    "probs_testp = model.classifier.get_probs(outclass_testp)\n",
    "y_testp = torch.argmax(probs_testp, dim=1).detach().numpy()\n",
    "\n",
    "# avg and std of cors\n",
    "cors = [distance_corr(X_testp[i,0], X_test[i,0].detach().numpy(), n_boot=None) for i in range(X_test.shape[0])]\n",
    "print(\"Distance Correlation avg and std:\", np.mean(cors), np.std(cors))\n",
    "print(\"NRMSE:\", (torch.sqrt(torch.mean(torch.square(X_test-X_testp)))/(torch.max(X_test)-torch.min(X_test))).item())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# selected = np.random.choice(range(1000), 7)\r\n",
    "\r\n",
    "fig, axs = plt.subplots(nrows=2, ncols=len(selected), figsize=(25,5), constrained_layout=True)\r\n",
    "for i, x in enumerate(selected): #selected):\r\n",
    "    vals = data_test_ori[x,0,:-1]\r\n",
    "    min_v, max_v = torch.min(vals), torch.max(vals)\r\n",
    "    axs[0,i].set_title(f\"C: {int(y_test[x][0])} (min={min_v:.2f}, max={max_v:.2f})\")\r\n",
    "    axs[0,i].plot(X_test[x,0])\r\n",
    "    axs[0,i].axis(\"off\")\r\n",
    "    axs[0,i].set_ylim((0,1))\r\n",
    "\r\n",
    "    axs[1,i].set_title(f\"Pred: {int(y_testp[x])}\")\r\n",
    "    axs[1,i].plot(X_testp[x,0])\r\n",
    "    axs[1,i].axis(\"off\")\r\n",
    "    axs[1,i].set_ylim((0,1))\r\n",
    "\r\n",
    "    print(\"cor:\", distance_corr(X_testp[x,0], X_test[x,0], n_boot=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_testp)\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "\n",
    "print(\"Accuracy:\", np.sum(np.diag(cm))/np.sum(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import Saliency\r\n",
    "gbp = Saliency(lambda x : model(x)[0])\r\n",
    "\r\n",
    "inp = X_test[7419,:,:].reshape(1,1,96).requires_grad_()\r\n",
    "\r\n",
    "r = []\r\n",
    "for i in range(96):\r\n",
    "    a = gbp.attribute(inp, target=(0,i))\r\n",
    "    r.append(a.detach().numpy().flatten())\r\n",
    "sns.heatmap(r, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false\r\n",
    "\r\n",
    "focus = 0\r\n",
    "\r\n",
    "for j in [1]:\r\n",
    "    if j == 0:\r\n",
    "        baselines = torch.tensor(gaussian_filter1d(X_test[focus,0], sigma=2)).reshape((1,1,96))\r\n",
    "    elif j == 1:\r\n",
    "        baselines = 1-X_test[focus].reshape((-1,1,96))\r\n",
    "    elif j == 2:\r\n",
    "        baselines = torch.ones((1,1,96))\r\n",
    "    elif j == 3:\r\n",
    "        baselines = torch.zeros((1,1,96))\r\n",
    "    else:\r\n",
    "        reps = 64\r\n",
    "        inp = inp.repeat(reps, 1, 1)\r\n",
    "        baselines = torch.rand((reps,1,96))\r\n",
    "\r\n",
    "    # input_attrs = get_shapley_values(inp, model, range(96), baselines)\r\n",
    "    input_attrs = get_shapley_values(X_test[3279], lambda x: model(x)[0], range(96), baselines=baselines, target_func=lambda x: (0,x))\r\n",
    "    plt.close()\r\n",
    "    sns.heatmap(input_attrs, cmap=diverging_colors, center=0).get_figure().savefig(f\"../plots/hm_{focus}-{j}.png\")\r\n",
    "    print()\r\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false\r\n",
    "\r\n",
    "for j in [1]:\r\n",
    "    if j == 0:\r\n",
    "        baselines = torch.tensor(gaussian_filter1d(X_test[focus,0], sigma=2)).reshape((1,1,96))\r\n",
    "    elif j == 1:\r\n",
    "        baselines = 1-X_test[focus].reshape((-1,1,96))\r\n",
    "    elif j == 2:\r\n",
    "        baselines = torch.ones((1,1,96))\r\n",
    "    elif j == 3:\r\n",
    "        baselines = torch.zeros((1,1,96))\r\n",
    "    else:\r\n",
    "        reps = 64\r\n",
    "        inp = inp.repeat(reps, 1, 1)\r\n",
    "        baselines = torch.rand((reps,1,96))\r\n",
    "\r\n",
    "    # input_attrs = get_shapley_values(inp, model, range(96), baselines)\r\n",
    "    input_attrs = get_shapley_values(X_test[3279], lambda x: model.encoder(x, False), range(24), baselines=None, target_func=lambda x: x)\r\n",
    "    plt.close()\r\n",
    "    sns.heatmap(input_attrs, cmap=diverging_colors, center=0).get_figure().savefig(f\"../plots/hm_{focus}-{j}.png\")\r\n",
    "    print()\r\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import ShapleyValueSampling\r\n",
    "\r\n",
    "input_feature = ShapleyValueSampling(lambda x: model.encoder(x, False))\r\n",
    "\r\n",
    "input_attrs = []\r\n",
    "for i in range(24):\r\n",
    "    print(i, end=\" \")\r\n",
    "    baselines = torch.tensor([np.random.binomial(n=1, p=1-x) for x in X_test[3279,0]], dtype=torch.float).reshape(1,1,96)\r\n",
    "    attr = input_feature.attribute(X_test[3279].reshape(1,1,96), target=i, baselines=baselines)\r\n",
    "    input_attrs.append(attr.detach().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(input_attrs, cmap=diverging_colors, center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer: importance of bottleneck with respect to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(get_layer_attrs(X_test[22], model, model.full_conv_bn, range(96)), cmap=\"coolwarm\") # for row i: attribution of neuron (24) to output i\r\n",
    "\r\n",
    "# bias = torch.nn.functional.leaky_relu(model.encoder.full_conv_bn.bias).reshape(1,1,24)\r\n",
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(25,10), constrained_layout=True)\r\n",
    "axs[1,3].set_axis_off()\r\n",
    "for i, x in enumerate(selected):\r\n",
    "    layer_attrs = get_layer_attrs(X_test[x], model, model.encoder.last_act, range(96), None)\r\n",
    "    ax = sns.heatmap(layer_attrs.T, ax=axs.flat[i], cmap=diverging_colors, center=0, cbar_kws={\"orientation\": \"horizontal\"})\r\n",
    "\r\n",
    "    ax = axs.flat[i].twinx()\r\n",
    "    sns.lineplot(x=range(96), y=X_test[x,0], ax=ax)\r\n",
    "    line = ax.lines[0]\r\n",
    "    line.set_xdata(line.get_xdata()+0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importance of input with respect bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(get_neuron_attrs(X_test[22], model, model.full_conv_bn, range(24)), cmap=\"coolwarm\")\r\n",
    "\r\n",
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(25,5), constrained_layout=True)\r\n",
    "axs[1,3].set_axis_off()\r\n",
    "for i, x in enumerate(selected):\r\n",
    "    neuron_attrs = get_neuron_attrs(X_test[x], model, model.encoder.last_act, range(24))\r\n",
    "    sns.heatmap(neuron_attrs, ax=axs.flat[i], cmap=diverging_colors, center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false\r\n",
    "for i in range(24):\r\n",
    "    a1 = feature_visualization(model, i)\r\n",
    "    plt.plot(a1, \"o-\")\r\n",
    "    plt.title(f\"Neuron {i}\")\r\n",
    "    plt.ylim(-0.05, 1.05)\r\n",
    "    plt.savefig(f\"../plots/{i}.png\")\r\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false\r\n",
    "\r\n",
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(25,10), constrained_layout=True)\r\n",
    "for i in range(7): #selected):\r\n",
    "    a1 = feature_visualization_class(model, i)\r\n",
    "    axs.flat[i].plot(a1)\r\n",
    "    axs.flat[i].set_title(f\"Representant class {i}\")\r\n",
    "    axs.flat[i].set_ylim(-0.05, 1.05)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapley Value Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(25,10), constrained_layout=True)\r\n",
    "axs[1,3].set_axis_off()\r\n",
    "for i, x in enumerate(selected):\r\n",
    "    attrs = [shapley_sampling(X_test[x,0], model, feature=j, n_batches=1) for j in range(96)]\r\n",
    "    sns.heatmap(attrs, ax=axs.flat[i], center=0, cmap=diverging_colors, cbar_kws={\"orientation\": \"horizontal\"})\r\n",
    "\r\n",
    "    ax = axs.flat[i].twinx()\r\n",
    "    sns.lineplot(x=range(96), y=X_test[x,0], ax=ax)\r\n",
    "    line = ax.lines[0]\r\n",
    "    line.set_xdata(line.get_xdata()+0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance of bottleneck with respect the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(25,10))\r\n",
    "axs[1,3].set_axis_off()\r\n",
    "for i, x in enumerate(selected):\r\n",
    "    layer_attrs = np.array([shapley_sampling_bottleneck(X_test[x,0], model, j, baselines, n_batches=10) for j in range(24)])\r\n",
    "    ax = sns.heatmap(layer_attrs, ax=axs.flat[i], cmap=diverging_colors, center=0, cbar_kws={\"orientation\": \"horizontal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(25,10))\r\n",
    "axs[1,3].set_axis_off()\r\n",
    "for i, x in enumerate(selected):\r\n",
    "    layer_attrs = np.array([shapley_sampling_bottleneck(X_test[x,0], model, j, n_batches=10) for j in range(24)])\r\n",
    "    ax = sns.heatmap(layer_attrs, ax=axs.flat[i], cmap=diverging_colors, center=0, cbar_kws={\"orientation\": \"horizontal\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapley value from captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(25,10), constrained_layout=True)\r\n",
    "axs[1,3].set_axis_off()\r\n",
    "for i, x in enumerate(selected):\r\n",
    "    baselines = torch.rand((1,1,96))\r\n",
    "\r\n",
    "    attrs = get_shapley_values(X_test[x], lambda x: model(x)[0], range(96), baselines=baselines, target_func=lambda x: (0,x))\r\n",
    "    sns.heatmap(attrs, ax=axs.flat[i], center=0, cmap=diverging_colors, cbar_kws={\"orientation\": \"horizontal\"})\r\n",
    "\r\n",
    "    ax = axs.flat[i].twinx()\r\n",
    "    sns.lineplot(x=range(96), y=X_test[x,0], ax=ax)\r\n",
    "    line = ax.lines[0]\r\n",
    "    line.set_xdata(line.get_xdata()+0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, bn = model(X_train, False)\r\n",
    "bn = bn.detach().numpy()\r\n",
    "fig, axs = plt.subplots(nrows=5, ncols=5, figsize=(25,20), constrained_layout=True)\r\n",
    "axs[4,4].set_axis_off()\r\n",
    "for i in range(24):\r\n",
    "    axs.flat[i].set_title(f\"Neuron {i}\")\r\n",
    "    axs.flat[i].hist(bn[:,i])\r\n",
    "    \r\n",
    "baselines = np.mean(bn, axis=0) # mean value of each neuron on the whole training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, bn = model(X_train, False)\r\n",
    "bn = bn.detach().numpy()\r\n",
    "\r\n",
    "y_train_np = np.array(y_train, dtype=np.int8).flatten()\r\n",
    "fig, axs = plt.subplots(nrows=5, ncols=5, figsize=(25,20), constrained_layout=True)\r\n",
    "axs[4,4].set_axis_off()\r\n",
    "for i in range(24):\r\n",
    "    aux = pd.DataFrame({\"Bottleneck\": bn[:,i], \"Class\": y_train_np})\r\n",
    "    axs.flat[i].set_title(f\"Neuron {i}\")\r\n",
    "    sns.kdeplot(data=aux, x=\"Bottleneck\", hue=\"Class\", palette=sns.color_palette(\"tab10\",7), ax=axs.flat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('.venv')",
   "metadata": {
    "interpreter": {
     "hash": "3d0a349251b803ce89bf9e449a94f1b8464b3ca029752d5a5598c6dc74984378"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}